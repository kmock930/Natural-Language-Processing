{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irwn0JOPk9gP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from data_extraction import get_raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MbGPV90quFO1",
        "outputId": "ad77201b-ccf2-4043-8273-cc55c25c532c"
      },
      "outputs": [],
      "source": [
        "### Training and Evaluation on Dev Set\n",
        "\n",
        "# Load raw data from jsonl\n",
        "X_train, y_train = get_raw_dataset(mode='train')\n",
        "X_dev, y_dev = get_raw_dataset(mode='dev')\n",
        "\n",
        "# Feature extraction: convert texts to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_dev_tfidf = vectorizer.transform(X_dev)\n",
        "\n",
        "# Save train and dev sets to a numpy file\n",
        "if (not os.path.exists('data')):\n",
        "    os.makedirs('data')\n",
        "np.save('data/X_train_vectorized.npy', X_train_tfidf.toarray())\n",
        "np.save('data/y_train.npy', y_train.to_numpy())\n",
        "np.save('data/X_dev_vectorized.npy', X_dev_tfidf.toarray())\n",
        "np.save('data/y_dev.npy', y_dev.to_numpy())\n",
        "\n",
        "# Train a Logistic Regression classifier\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2xJa5YFuGbJ",
        "outputId": "6cbd3717-f851-4d0d-d9e3-eedefda62290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation on Dev Set:\n",
            "Accuracy: 0.5754\n",
            "Macro F1: 0.5316\n",
            "Micro F1: 0.5754\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the dev set\n",
        "y_dev_pred = clf.predict(X_dev_tfidf)\n",
        "acc = accuracy_score(y_dev, y_dev_pred)\n",
        "macro_f1 = f1_score(y_dev, y_dev_pred, average='macro')\n",
        "micro_f1 = f1_score(y_dev, y_dev_pred, average='micro')\n",
        "\n",
        "print(\"Evaluation on Dev Set:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "print(f\"Micro F1: {micro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecTeweeduJnV",
        "outputId": "ff2064ba-562a-475c-b3ed-8a4c6bf87eb5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_file' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Prediction on Test Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load test data (this file does not include labels)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_test \u001b[38;5;241m=\u001b[39m load_jsonl(\u001b[43mtest_file\u001b[49m)\n\u001b[0;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m ids_test \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_file' is not defined"
          ]
        }
      ],
      "source": [
        "### Prediction on Test Data\n",
        "\n",
        "# Load test data (this file does not include labels)\n",
        "X_test, ids_test = get_raw_dataset(mode='test')\n",
        "\n",
        "# Transform test texts using the same TF-IDF vectorizer\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "y_test_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "# Save data to a numpy file\n",
        "np.save('data/X_test_vectorized.npy', X_test_tfidf.toarray())\n",
        "np.save('data/ids_test.npy', ids_test.to_numpy())\n",
        "\n",
        "# Define a relative path for the output file\n",
        "relative_output_file = os.path.join(os.curdir, 'content', 'Result_baseline.jsonl')\n",
        "\n",
        "# Write predictions to the output file in JSONL format\n",
        "with open(relative_output_file, 'w') as f:\n",
        "    for id_val, label_val in zip(ids_test, y_test_pred):\n",
        "        result = {\"id\": id_val, \"label\": int(label_val)}\n",
        "        f.write(json.dumps(result) + \"\\n\")\n",
        "\n",
        "print(f\"\\nPrediction file '{relative_output_file}' has been generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/model_baseline_LogisticRegression.pkl']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Saving the model\n",
        "if (not os.path.exists('models')):\n",
        "    os.makedirs('models')\n",
        "joblib.dump(clf, 'models/model_baseline_LogisticRegression.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
